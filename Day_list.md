1. 炉号和膜厚设置值匹配对应好; model2的微调std index 和 std 修改值, 落盘并在运行modle1时自动读取 [done.!]



2. 增加一个, 我们算法model1,2 调优完成后, 所有数据lab ok 的数值?
[优先级较低], 因为我们模型优化推理得到的lab曲线,并不一定是真的镜片膜厚设置修改后会得到的曲线]





0726：
model2.py flag == 0, 单独处理每一个样本
1. 每个炉号的膜厚修改情况单独写入一个.txt, 所有的txt统一放文件夹下.



lab曲线好不好，非常依赖model2的flag=1的拟合好坏 


为什么,单独一条样本送进入 各个样本基本一样不受模型变化
但是集体样本送进去，样本件就会有差异？,难道还是scale的bug???,是的就是因为它！！！只有一个样本的时候，scale完x变全零....omg！！！
需要手动: x = (x-mean)/std


兜底方案: [效果很粗糙...]
model2也出现微调阶段训不动的情况 输入端的梯度都不变 
[感觉这个是很有必要的，毕竟不同的样本之间，需要区分的进行微调]
微调阶段的lr，可以尝试把代码写成超参搜索，达到一个模型自主选择的过程[这个是ok的~]
在model0726_2056.py中实现了~



思考为什么训不动? 
首先， 曲线变化了，证明data端一定是改变了的。 为什么训不动，可能是因为 81维度上，81个点的loss/grad 差异太大。应该根据std区分开? 
打印了下 每个epoch的梯度都不变的? 14维完全没变化

或者，还是因为model2的flag=1拟合的不好?????


分析:
14维的std, 非常非常微小的改变，会带来曲线很大的变化... mse也变化挺大的. 如: 0.82 -> 0.26 ... [这不就是model2.py flag == 1过拟合了...] 但, 也可能真的梯度不好传...



做一个14 std 到 10维曲线的映射?,看看改std对10维影响大不大???,[在loss里把剩余的71维weight置0就好~] [还是一样, std变化很微小很微小，但mse会有蛮大变化...]
梯度太大了???


猜想，model2的输入之间，太相似了, 数据标准话一下之后diff就更小了... 模型就很难学习好 x几乎一样，要去学出不同的y...[可视化一下所有的std x, flag=0阶段的...]
[猜想错误, X样本之间diff还挺大的...]

另外: 为什么一起放入微调, loss会出现一下下震荡 虽然是很数量级的 1e-5之类的... 可能浮点误差把....



1. 还是model2 flag=1没有拟合好...?????

比较粗糙的一个方案:
1. 保持现在的model2, flag=1用所有数据拟合, flag=0用大清洗内的数据微调. 虽然loss训不动, 即模型只在第一个epoch时候微调,
可将lr设置为搜索方式, [0.1, 0.5]范围, 得到最接近标准曲线的结果.


[-0.011027330404737648, -2.208806477669678, 6.622097480408985, -3.2976394279664483, 1.5343488411920534, 1.6141188966010322, 0.29986237455439585, -0.15545047819867958, -3.080210235829034, 6.733569497337689, -3.654895367395472, 2.0634
906119490273, 2.493694672091455, 0.33964004330412745] base
epoch 0, data: [9.627114343289009, 5.0495741234793945, 5.537281495528722, 12.744503803760189, 35.33844104788958, 35.66846629389466, 14.77861505547356, 9.347839212916213, 4.690999663843107, 5.5335705701323175, 12.458338763885454, 34.
77463461236881, 35.69159889415467, 14.836498464306066]
data value:,[-0.01102733 -2.2088065, 6.6220975,-3.2976394, 1.5343488, 1.6141189
,0.29986238 -0.15545048 -3.0802102, 6.7335696,-3.6548953, 2.0634906
,2.4936948, 0.33964005]

,std 1e-7级别的修改, loss那边的响应: 



尝试数据不做归一化处理?
flag=1 拟合出现"尖"频段突变, flag=0也基本不改变输入的原始std值

用了一条validation的数据做flag=0微调, 实验结果类似,应该也不是flag=1阶段过拟合的原因.[用了train中见过的数据做微调，所以flag=0训不动..]

另外发现的一个问题:
1. 微调阶段, y端使用标准曲线或本身样本的lab曲线, 模型输出的data调整结果都是一样的....[y端的变化很难体现到x端???]



0727下午 bug修复, 微调data阶段写错了... data端写死了.. 现在flag=0阶段是可训动的...




epochs - 1 保存std的修改值
epochs - 2 保存优化后的lab曲线
epoch_test = min_loss_index + 2



[0, 1, 2, 6, 8, 10, 12, 13]

['9.425756765370902', '6.181887926323517', '4.369867714469095', '12.928751934461658', '5.523693280069558', '12.94975895436975', '34.34616070029068', '14.772689997459405


[[ 25.3, 13.,,37.59 106.2, 96.2, 24.68,12.7, 36.67 103.9, 94.9 ]]
[[-2.92304886e+12 -4.72496495e-01,1.73475908e+13,3.69909836e-01
, 6.21964638e+00,0.00000000e+00 -1.54735694e-01,5.86962124e-01
, 4.10325508e-01,7.03396126e+00]]



, [ 25.35,12.96,37.17 106.4, 93.4, 24.68,12.62,36.67 103.6, 92.4 ] ==

[-0.41539023 -1.04446594,0.58696212,0.49145164 -1.19785782,0.
 -1.04446594,0.58696212,0.18562344 -0.31972551] ==



 不应该用一个周期内的thickness mean 和 std 而是用所有样本的 [在model2.py中就记录下来...,不然std值太小了...],[done.]






利群样本拉出来试试，看调整效果,[ok的~]
线上通路是否可调.. 代码足够自动化。


算法运行步骤: 
1. 全量数据, model2.py flag=1, 拟合sensor std值到lab曲线的模型 
2. data_clean_cycle.py 生成一个大清洗周期内的所有炉号.
3. model2.py flag=0
, model2.py flag=2, lab曲线调优
4. thickness10_modified.py flag=1,std修改值统计

5. 使用一个大清洗周期内的所有数据去, data_clean_cycle_model1.py flag = 1 拟合膜厚到lab值关系
data_clean_cycle_model1.py flag = 0
data_clean_cycle_model1.py flag = 2
thickness10_modified.py flag=2




# 0729 
【模型最后需要优化的项: model2 flag=1的拟合, 需要更准确, loss降低要0.5以内最佳!!!】


部署流程走一下：
to do list:
1. 继续优化model1的拟合, [ok, lr=0.001就差不多..~]
2. 1月的 '33321012501' 测试算法
3. 把所有清洗周期分出来, 然后各个model1 flag==1的mlp.pth落盘
细节: 
model1的flag=1使用全部的大清洗周期内的数据拟合, 但拟合的std index是单个样本的std index..
所以需要代码过一遍整个清洗周期内的数据, 然后汇总需要拟合的indexs,
再根据这些index, 用所有的周期数据拟合model1, 落盘.pth [lr:0.001就差不多可以]
[注意,这一步拟合model1,部分数值没拟合上也不用太担心, 本来index就是所有样本的一个set集合~ ]
新来一个样本, 在所有model1.pth中找最接近的那个.pth, 然后继续modle1的 flag=0,2调优~



1. 蔡司膜厚推优项目算法打通，在完善线上部署代码，本周五下午给到客户反馈，开始推进线上测试验证
2. 首次接触安世半导体投标项(工业调度生产问题)，正在理解数据和问题背景。

1. 跟踪蔡司反馈, 继续算法部署，配合软件开发等工作...
2. 安世半导体投标项继续理解+初步处理数据。

蔡司项目confluence文档: http://192.168.5.103:8090/pages/viewpage.action?pageId=22675710




数据需求: 
1. 本产品数据持续供给. (刚会议澄清的,model1分周期拆分建模, 所以需要比较多的数据支持新样本选择最接近的机器状态)
2. 等待差异数据(膜厚到曲线, 曲线到膜厚.) 我们这边会使用model1,2结合验证.
线上验证: 
1. 等待产线online验证.. 





0731 / 0801 to do list:
1. deta 方案可以尝试
2. 根据loss 降序排序, 洗出若干不同的model1.pth(而不是清洗周期..) 
3. 安世..


# 0731 关于验证模型效果和正背面修改推荐方向一致性的问题
遗留问题:
1. 0731李工补充:
如果没有正被差，说明两个面的颜色是一样的，那么他们的调节方向也应该一样，当然也有可能有不同的解，不过我担心这个会引入正背差
【正背面的调节方向是否一致是个问题. 会生产出两面, 说明正面的单面曲线是ok的, 但正背面设置值不同, 多少都是会产生正背面色差吧? 会单独测一下背面的曲线orlab
值吗? 技术上是可操作的吗? 】
李工解答:
由于镜片是有弧度的，所以正背面膜厚设置肯定不一样才可能得到同样的膜色。大体上背面会比正面多1-2%左右吧

结论: 
好的了解了。那比较直观的理解来说，还是尽量希望正背面膜厚调节方向是一致对的。因为目前给到的都是测量过的无正背色差数据。 


0731实验记录: 
1. 理论上, 蔡司给的3条测试数据, 属于同一个清洗周期比较正常[这个倒是都是, 都最接近model1中的index=6, 是个好消息..]
2. 找到最接近的model1状态后,要去finetune下model1, 不然效果很差...
3. 那就把3条都加进去finetune呗.,加了,还是有点偏差....



# 分步走吧..
1. 直接用三条数据的真实std值,输入model2, 看看lab情况是否和真实lab一致,检验model2的正确性.,model2就有点不准...
[还没办法finetune, 他们真实lab曲线没给到...]
[猜想: model2也和清洗周期有关系, 将validation和train根据周期划分, 0~3validation, 4~16train.]
会有个问题, model2的数据量就会小一些些(少了10条而已, 有578条), 因为第三批数据中的一些炉号和周期对不上,周期性未知..

2. model1的不准倒是可以通过loss直接体现出来, 并且finetune后loss会小挺多的..

0802:
需要把model2也按照周期拆分开...
mm_Model2_data_cycle.py
1.所有的数据先train有个base总model2.pth出来, 然后各个子周期的数据去做fine_tune,保存为新的16个model2_{}.pth
为什么这么干呢? 不做finetune直接训每个cycle数据的话, 数据量太少了,每个cycle模型的拟合效果不会太好.. 



test： 33321020305,cycle 0





0802：
model1很依赖测试数据的fine-tune. [即选中了最贴近的model1_{}.pth, 然后还是要拿测试数据去fine-tune下这个子模型, loss下降会很明显.
loss 十几甚至几十, 可以降到1一下]
[猜想: 可能因为, 本身model1的各个子模型,见的数据都比较少,fine-tune会是个很必要的过程..]


[model1没必要做all data base model训练再单独每一个data cycle finetune...]???? 存疑, 晚上试试看, 效果会不会更好.



过来的一条测试数据, model1要fine-tune, model2不要.




# 0803 
根据lab曲线去逼近: 
24.11 5 12.42 36.85 102.73 93.9325 25.07 5 13.20 37.19 104.42 94.26 25



根据R3去逼近:
正面: 24.08 5 12.57 36.86 104.00 93.48 25 
背面: 25.06 5 13.15 37.21 104.60 94.08 25

24.46   5   11.7    36.34   102.2   93.6    25      24.95   5   12.4    37.07   107.65  97.1    25
24.46   5   11.7    36.34   101.5   93.95   25      24.9    4.99    12.38   36.99   105.8   95.8    25



1. 数据需求:
扩充加鲁棒 model1 model2


2.寻找model1的loss最小, 然后就找到了part_data_cycle{}.txt 
part_data_cycle{}.txt + 本条测试样本, 然后去拟合本样本显著改变的几个std值.
再计算膜厚修改值..




# 0803 结论:
1. 正向验证, model12均需要用测试数据fine-tune最佳model12
2. 反向验证, model12均不需要用测试数据fine-tune最佳model12

# 0803晚上  to do list. 
3. deta 方案可以尝试
2. 根据loss 降序排序, 洗出若干不同的model1.pth(而不是清洗周期..) model1, model2都需要洗. 



# github readme backup
算法流程:
===

model2 part: 
---
1. 使用所有给到的数据拟合model2[无需区分清洗周期, 尝试过区分清洗周期, 模型拟合的反而不好, 可能因为一个周期内数据量太少..]，对应运行: model2.py flag == 1
2. 运行 data_clean_cycle.py 脚本, 生成某个大清洗周期内的数据列表, 将其录好信息记录在 './part_clean_number.txt'中.
3. 进入微调阶段, 读取'./part_clean_number.txt'文件, 获得本清洗周期内的所有待优化炉号. 
运行 model2.py flag == 0，2, 模型可通过调整14维 ACT_O1_QCMS_THICKNESS_CH1 std 值优化lab曲线.
[0阶段为lr,epoch等超参搜索阶段,2阶段是最佳参数配置下的微调过程]
4. 运行 thickness10_modified.py flag == 1, 获得14维 ACT_O1_QCMS_THICKNESS_CH1 std 的变化量.
记录修改幅度最显著的[如超过0.1%] std index[索引位置] 和 修改百分比. [为什么不记录所有14维呢? 因为这样的话modle1非常非常难拟合...]


model1 part:
---
1. 开始拟合model1, 根据以上得到的 std index[假设有8个index], 以10层膜厚为输入, model1负责拟合这8个std值.
运行 generate_model1s.py flag == 1 即可完成.
2. 进入微调10层膜厚阶段, 将model2 part 中得到的 std 修改百分比, 复制到模型的输出端[y值].
运行 generate_model1s.py flag == 0,2, 即可在modle1训练过程中, 通过调整输入值x, 得到我们想要的输出值y的变化.
落盘本清洗周期内的, 所有10层膜厚的修改前后数值[.npy保存] [0阶段为lr,epoch等超参搜索阶段,2阶段是最佳参数配置下的微调过程]
3. 运行 thickness10_modified.py flag == 2, 统计正背面10层膜厚各层的变化百分比和变化数值. 落盘 './modify.txt' 文件.


附:
===
为什么model1突然work了?
---
首先model2使用所有的数据拟合，然后在clean周期内，进行model2的微调，并得到响应修改最大的sensor std index，用于作为model1的输出y.(拟合所有的16维没有必要以及非常难将model1训好； 
之前尝试过的只拟合4个std值，model1可train出来但微调阶段训不动，这个可能当时代码里有一点bug, 加上我没有剔除正背面的第一个std值，这俩都是0.没有拟合必要。)

scale 统计值
===
modle1,2的输入都需要进行normalization. 统计量mean和std, 应该用全量数据的mean,std(包括thickness,sensor std), 而不是一个大清洗周期内的mean,std. 

优化超参
===
1. 针对model1,2的微调阶段, 可对 lr 和 epoch 进行超参搜索, 记录下最佳lr下最小loss对应的训练epoch次数. 落盘到临时文件. 
2. 将此套超参设置到模型中, 再run一遍模型, 即可得到最佳的输入端偏移量, 自动化优化出更好的lab曲线和sensor修改值. 

部署流程: 
---
将Model1按照大清洗周期拆分: 

1. model1的拟合, lr=0.001比较好[经过了lr超参搜索],也可以开启lr超参搜索得到最佳lr设置值.
2. 1月的 '33321012501' 测试算法
细节: 
1. 之前验证model1的性能, flag=1的拟合使用大清洗周期内的所有数据拟合, 但拟合使用的std index是单个样本的index..[由model2 flag=2后,再使用thickness10_modified.py统计得到]
2. 新来的待优化数据, 大清洗周期背景知识未知, 故需对当前的各个清洗周期内的数据过一遍model2 flag=2, 汇总 std index set，用此set拟合各个各个周期的model1.pth
3. 所以需要代码过一遍整个清洗周期内的数据, 然后汇总需要拟合的indexs,再根据这些index, 用所有的周期数据拟合model1, 落盘.pth  
[注意,这一步拟合model1,部分数值没拟合上也不用太担心, 本来index就是所有样本的一个set集合~ ]
4. run n_modle_pths.py 即可实现各个周期内的 std index set 统计.
[实验发现基本 index set 都是 range(16) 剔除0,8. 因为周期内的样本基本可以把14个index值塞满]

5. run generate_model1s.py 得到各个data cycle 的 model1.pth, 并落盘.

6. 新来一个待优化样本, 在所有model1.pth中找最接近的那个.pth[loss最小], 然后继续modle1的 flag=0,2调优~


总结
===
了解工艺背景，熟悉起数据，建模需要对数据敏感，抽哪些数据特征作为输入，模型的输出是什么，拟合几个模型？
bug free很重要，不然一直不顺一直调模型换思路，很崩溃。 代码细节很重要！
需要注意机器的工艺周期性。蔡司这边情况，拆分出model1,2，两个子model也均受到周期性的影响:
      需要把model2也按照周期拆分开...   
 步骤:  1. 所有数据先train一个base总model2.pth             
           2. 各个子周期的数据去做fine_tune,保存为新的16个model2_{}.pth
为什么这么干呢?  不做finetune直接训每个cycle数据的话, 数据量太少了,每个cycle模型的拟合效果不会太好.. 


实验记录:

0803: 
1. 实验现象:
0731蔡司给到的数据, 只有CS-CX那条, model12的正向验证最差, 其他几条都拟合的不错. 是因为原第三批给到的数据,
没怎么见过异常样本吗? [蔡司之前提到的, 异常样本不太多,像正面不合格了马上会调整正面膜厚值再镀背面..]
所以数据[尤其lab失败的离群数据]还是很关键的... 
[猜想: 不同的model12_{}.pth难道就是拟合出了不同的b? 异常一些的数据正向不好, 就是没见过这个b; 稍微正常的数据, b小一些, 则正向拟合, 基于
第三批数据的各个modelk12_{}.pth, 就拟合的还行? ]
用第一条不通过曲线，且model12不fine tune 做反向验证，不太对。 因为它的正向验证就得不到它的真实lab曲线，基于这两个不够“真实”的黑盒去微调两个输入端，是不太对的
一定要正向验证ok了，才能反向优化lab曲线，然后回推膜厚修改值
可以试试第四条不通过的数据。 用fine tune过的model12，做为两个过程的基础model。  如果无法优化得到好的lab曲线，也即调不动，只能说明原来的模型没见过这类离群样本。那就只能用原来的15个cycle为base，调一个cycle数据一一test，走一遍正反向验证。
如果可以调动，得到比较接近标准曲线的lab结果，且model1的拟合loss也较小（小于3？）则可以看看推荐修改的膜厚，和R123几条通过膜厚设置情况是否类似。



2. 共16个周期, 抽一个作为test, 在剩下15个里进行test.
[part_clean_number15.txt test, 其他为train..]



找一个第一条不那么离群的周期, 用周期内的第一条数据找最优model1 2, 且只用第一条数据去fine-tune model1 2. 
用得到的model12 去做model1+2的正向拟合. [对着本周期内的各条数据.]
[选了: part_clean_number15.txt, model12_15.pth]




线上测试备选方案:
1. 正向model1+2, 基于每条测试数据, fine-tune各自的最佳model12, 然后做优化lab和反推膜厚推荐值
2. 正向model1+2, 基于第一条测试数据, fine-tune第一条的最佳model12, 然后固定这俩 model12 
针对每一条测试数据做优化lab和反推膜厚推荐值   [这个感觉不是很ok, 不试了, 直接上3.]
3. 实时更新模型, 给到的测试数据, 来了之后, 测试完就加入数据库fine-tune下条测试数据的 best model12. 


试过了每条数据fine-tune大model2.pth的实验, 效果不是很好,还是得区分data cycle.


1. 当前样本不加入到它的best model.pth fine-tune的话, 正向不会太好. 
所以还是得当前样本加入自最佳model ft   [但担心模型被fine-tune的偏离最初状态...]
2. 持续把测试样本加入 fine-tune 当前的 best model[但不把自己放进去ft], lab曲线持续变好. 但效果不及1.
3. 持续把包本身的样本加入本身的最佳model去ft,正向会好一些.



0805: 
1. 把测试的所有数据[线上测是给3炉]去finetune各个测试样本的最佳model, 看看效果会不会好一些?
【也可以所有数据中, 剔除自身这条样本,去ft】


2. 思考:
为什么太异常的样本, model12正向输出的结果容易向best曲线靠近? 





线上测试流程:
1. 数据准备:   
run Test_ycy.py 生成测试数据的.json文件. 
[需要在 r'./sensor_csv.txt' 里把给到的3炉数据的name手动写好]
[number33_evtpair.json 文件也要自己手动写, 就是炉号和对应的evts对]
[thickness_list 要手动自己写好, 膜厚顺序是: 背+正]

2. run ycy.py 正向验证lab曲线是否拟合ok. 
3个方案: 
1. 本测试样本ft本最佳model12,验证正向ok,然后进行反向优化lab,推荐模厚值. 
2. 持续接入除本身外的样本, ft当前最佳model1,2, 但实测不是很ok的样子  这个也写好脚本,正向check+反向推膜
3. 持续接入包含本身在内的样本, ft当前最佳model1,2, 准备好脚本,正向check+反向推膜
兜底: 可能对于不同炉的数据,适用不同的方案,可以拆分开的独立每一炉去找最佳正向拟合方法,然后保存下model12.pth, 用于反向膜厚推荐



to do list:
维护好model1_{}.pth 和 model2_{}.pth
1. 按照loss拆分model1: 拆到后面loss训不动, 降不下来.  [这是为什么, 要再思考排查下...]

[丰富, 鲁棒model1_{}.pth是关键!!!]

2. 针对每个model1_{}.pth进行fine-tune, 然后选loss最小的那个model. [done.]




原:         24.46,  5 11.6,  36.34, 100.6,  92.3   25    24.8, 5  12.2,  36.88,  103.6,  94.8   25
model res:  24.45,  5 11.61, 36.34, 100.6,  92.86, 25    24.8, 5  12.23, 36.88,  103.76, 94.53  25

第二条测试数据:
           24.46, 11.6,  36.34, 100.6,  92.86  24.8   12.23, 36.88,  103.76, 94.53   
model res: 24.46, 11.44, 36.34, 100.43, 93.26, 24.81, 12.19, 36.88,  104.01, 94.18 



实验记录:
model1的hiden_dim是一个可调整参数, 目前来看[300]可让模型loss更小, 但也有过拟合风险.




0810 to do list：
1. co哥蔡司案例描述  [done.]
2. moyu 膜色曲线推理[3维扩充到6维] [done.]
3. 膜厚推优再优化... [doing...]


# 下午的非常异常数据测试: 
上午的较正常数据:      24.46   11.6,   36.34,   100.6,   92.3      24.8    12.2,    36.88,    103.6,    94.8  

下午的异常数据:         25     10.5     35        96      90      26.04     12      38.53    108.95    99.26 
模型针对下午数据的推荐: 25.05,  10.57, 35.08,    95.57,   89.51,   25.97,   12.05,   38.52,   108.63,   99.43 

原曲线lab:  (6.89532583924927, -5.1910853157585, -9.77204478258773)
调整后曲线lab:  (5.802554045356351, -5.281641141923712, -10.05911927829774)





# 0811 to do list 
1. 离群数据统计, 包括膜厚设置和lab曲线的离群
2. mlp的激活函数可以研究下 relu, sigmod?
3. model2精调, 确保model2 1 都是很精准的!!!!
[做了手动把离群样本剔出来, 并且2:1拆分到train val中, 训一个base model2; 再针对每一个清洗内的所有数据, 基于base model2 fine-tune]
[针对每一个清洗周期内的ft就没必要拆分val和train了吧.]




1. 离群点怎么定义?
model1的那些loss很大的, 难收敛的那些炉?



2. model2 450~500频段加权...  [done  420~460 loss加权]  
[不是很有效的样子, 会使得修改膜厚diff很小.... 看样子其实model2的鲁棒也非常的关键的...]
[根据明天的实测数据再看要不要加 model2 420~460 加权..]
晚上:  [只用model2.pth 效果也不错的样子... ]  
所以还是根据明早的数据实测吧...


3. 前向阶段, model2不根据测试样本去fine-tune.  online_test_ind_add1.py  [done.]
4. 膜厚推荐阶段, model1要做一个超参搜索 [done.]


下午的这批数据就不加入微调了吧  因为不清楚清洗周期  别弄混乱之前的model12 

0812实验:
1. 只用一个model.pth的话, 正向lab曲线拟合没那么准, 膜厚修改推荐会倾向很大(0.5~3这种级别.. 有点不稳..)


测试记录:
1. 第一条: model1用了ind+1的数据持续入库ft, model2没有tf [正向拟合曲线450~500阶段偏高, 模型推荐膜厚修改幅度较大] 
[这里应该用model2ft的,这个大幅度修改导致了正面的后两层有点太小了...]
2. 第二条: model12均用了ind+1的数据持续入库ft [正向拟合曲线很贴合, 模型集中推荐正面的后两层, 幅度约0.7 0.8]
thickness:

base:       24.46 4 11.6  36.34  100.6  92.3   25  
            24.82 4 12.2  36.88  103.6   94.8  25

model res1: 24.86 5 10.97 36.73  98.92  89.97  25  
            24.43 5 12.03 36.83  101.9   94.24  25 

model res2: 24.87 5 10.76 36.72  98.9   89.95, 25  
            24.38 5 12.05 36.84  102.65  95.12  25


model res3: 
       正面: 24.94, 5 10.88, 36.67, 99.31, 90.16,  25

       背面: 24.19, 5 12.21, 36.83, 103.68, 96.23  25






0813: to do list 
1. 通过loss找到最接近的model12 index, 然后拿到这个周期的数据, 和测试数据一起在base model12上做finetune. [done.]


改ppt 
1. 为什么拆分model12  总的一起拟合的不好?  还是说膜厚到lab是会一对多的..
2. data 抽象出一个特征提取类  包括 膜厚 std lab (sensor的mean std, 晶振频率等..)
3. 不同参数 配置 整合成config 方便后面问题迁移使用..  






0817：
1. model2 无论怎么fine-tune 都会使得膜厚推荐值变化很小..
试试不做ft呢?  不做ft不行, model2的loss也能达到1.+的数值
那么, 折中下, ft的epoch数小一点???  ft 50个epoch

base:       24.46 4 11.6  36.34  100.6  92.3   25  
            24.82 4 12.2  36.88  103.6   94.8  25

model res1: 24.86,5,10.97,36.73,98.92,89.97,25,  
            24.43 5 12.03 36.83  101.9   94.24  25 

[24.95, 11.84, 36.01, 99.29, 93.41, 
24.55, 11.65, 36.86, 101.96, 93.22]

model res2: 24.87 5 10.76 36.72  98.9   89.95, 25  
            24.38 5 12.05 36.84  102.65  95.12  25


model res3: 
       正面: 24.94, 5 10.88, 36.67, 99.31, 90.16,  25

       背面: 24.19, 5 12.21, 36.83, 103.68, 96.23  25


# 0817模型正向验证:
1. tuning可以拟合出好的曲线, 但一定程度上改变了实际机台生产关系吧.. 
2. model1不做tuning呢?
model1的不准程度, 大于model2




1. 集中精细调model1 包括hidden 层数 维度 等  16维感觉也是可以拟合的...
2. model2 的 550频段拟合 精细化  400频段>10的先剔除掉..
3. 统计下一个清洗周期内 晶振频率 等变化是否大: https://shimo.im/docs/y8ypyPhqdcR3wt6p
4. 


0818：
1. model12_check.py 基于第一条测试数据固定下来的best model12, 第二条数据数据过来, 简单fine-tune下model2(25 epoch就够了), 模型输出可以得到与真实数据lab曲线拟合不错的结果
model2的映射关系还是相对准的.

2. 集中看下model1 
打印看了model1的参数, 数值也不算大啊, 1e-1 1e-2这样的数量级
貌似回归16个std值比14个好? model1 loss可以更小???
测试时候, 减小model12的fine-tune epoch数 
[志哥说的那个造数据是啥意思??]
model12的epoch数都减小到25, 模型的推荐结果:
[0.22, 0.32, 0.28, 4.32, -0.8, 1.19, 0.98, 0.09, -0.7, 2.68]


[0818初步方案: model12 tuning epoch 数目减小到25]

针对model1 把异常样本剔出来..
model1 不拆分开数据的话, 是存在一对多关系的 一个膜厚设置x 可能对应多个 std y


model1中loss很大的那些认为是异常样本的剔出来.. [done.] 剔出了50个
[但是, 没有这样的异常样本, model1作用到测试数据上, 效果非常差.. loss很大..]
感觉重点在model1  得多见见异常数据.
正: [0.14,  0,  0.8,  0.6,  0.31,  0.94,  0]
背: [0.65,  0,  0.58, 0.01, -0.5,  1.54,  0]

异常样本分布周期: [10,3,5,4,3,2,4,3,3,16,4,3,4,5,13,5,3,4,9,9,4,5,16,5,16,10,16,14,4,14,7,15,3,9,10,9,5,4,10,4,5,9,11,11,4,9,1]

尴尬了啊, 一个清洗周期内也存在一个x多个y的问题...  那就不能按着之前的,简单的利用清洗周期划分数据啊...


1. 不区分清洗周期, 洗出一个481的无重复集合, 然后剩下的重复2次的一个集合, 有重复3次的再一个集合 [剩下两条重复了4次的, 就不单独处理了..]
拆分得到 data1.json data2.json data3.json  分别train出3个model1.pth loss也较小了, 但迁移到未见过的测试数据上, loss 很大..
model1 过拟合了?   [validation的必要性, 直观显示, train data上模型是否过拟合 ]



'33121051807', '33121051808', '33121051809', '33121051801'


1. 排期 项目  知识储备起来~
人工免疫算法
# makespan minimization problems
# job shop scheduling problems
# Flow-Shop-Scheduling
# Flexible job-shop scheduling problem
看看文献...


蔡司:
兜底 砍目标 只做平稳周期内的维护





0819: 
1. validation检测, 排除model12的过拟合问题..

2. 尝试, sensor mean 作为枢纽
model1的loss更大, train 900 epoch 就差不多收敛了, loss 8.8
可以在测试数据上试试  需要重新生成测试数据的 finally.json  [猜测效果不会太好...] [实验完了, 效果确实很差..]

3. model1走两种?
各个周期直接自己train起来 
总数据train出个base  然后各个data cycle fine-tune.

4. 重新做了part_cycle_txt 划分
0~15个 [a, b)

5. 重新生成新的part_cycle_txt对应的 model12_{}.pth
model12.pth 均是全量数据训练得到的base model
model2_{1-16}是基于base model2.pth, 针对每个cycle data fine-tune 得到的各子模型
model1_{1-16}是直接每个cycle data train 得到的各子模型
model1_{17-32}是基于base model1.pth, 针对每个cycle data fine-tune 得到的各子模型

run ycy.py 前后 best model12 寻找 + 25 epoch 微调, 初步结果是, 
model2 需要使用最佳model2 index 对应的 cycle data, 且测试数据持续入库, 基于 base model2.pth tuning..
model1 不需要, 直接找到最佳 model1， 然后测试数据持续入库 tuning即可.~



测试数据上来, 在model1的loss还是很大, 这个还要好好思考下!!!




0820:
会议:  [并不是今天 还没约上客户.. 预计下周..]
1) 膜色缺陷: 
1. 正背差用零部分 rgb 的差值判断, 蔡司是否能接受   2. 用重叠区域的颜色rbg值, 拟合lab曲线, 这个验证项, 蔡司能接受的误差? 


0820 膜厚推优会议纪要:
1. 展示了清洗周期内四条相同膜厚设置不同lab曲线的情况. 李工那边的建议是, 太异常的数据可剔除, 后续机台验证遇到这种情况的话, 考虑是机器出了问题, 即使模型给出的结果不ok, 也不算做验收考量.
2. 给到的条件概率项参考: 
1) 晶振频率会影响膜厚(一般晶振片四次一换: 正正背背. 第二面的正背都比第一面的正背厚一些, 所以第二面的正背膜厚设置值会调小些)
2) evtxxx.csv中 start -> step1 这个过程耗用的时间, 可评判机器的干净, 脏程度(耗时短机器干净， 耗时长机器脏.).  这个信息也可加入模型参考.  (一个清洗周期内或跨周期都可考虑下这个信息)
3. 每一炉内第一层数据最反应机器真实状态，第四层数据最反应整炉数据的质量合格率情况。后续分析机器状态也需要多关注第一层数据.
4. 项目时间节点: 10月中出1台机器推优.  正背差暂时不考虑(pm说的不考虑 但还得跟商务确认, 不做正背差的话, 蔡司估计不会买单..)   后续会扩充到6台，这个时间再根据后面排期。 
需要给pm的输出: 
5. 下周一二左右, 出一个算法节奏节点表 (得志哥安排)
6. 输出一个文档(也下周一二吧): 目前遇到的问题, 需要蔡司配合的资源什么的 
(主要就是要蔡司的数据吧，然后模型效果快速验证需要工艺李工帮忙多check，看模型的输出是否符合经验. 



周报:
蔡司膜色推优:
1. 调整算法方案, 在跟客户保持模型结果快速验证沟通, 等待正背面数据加入.
2. 本周五上午跟客户对齐了一些数据和验收疑问, 准备将一些客户提供的工艺方面辅助信息加入建模

蔡司膜色缺陷(poc):
1. 本周一给到了一批新异常数据, 算法做了初步尝试,感觉有希望做, 还需要pm约客户对齐技术规格和验收要求。


1. 数据处理这块
说需要剔除异常数据，感觉同样膜厚的不同数据如果差别不大都可以保留，差别很大就那段时间段全剔除？

背背正正 后俩厚于前俩 这个信息暂时不知道咋用 

evt start->step1 时间信息取出来   添加到 data_post_process.py, get_evtpair_info()函数中..  [done.]

每一炉的第一层数据 仔细研究下

重构下data_post_process.py, 膜厚顺序调整成: 正+背  [done.]


xixi:
1. 不区分清洗周期, evtxxx.csv中 start -> step1 这个耗时信息用上, concat维度用到模型中 or  影响weights 
只两个模型 不需要各个周期分别 train 出model12_{}.pth  类似transform 的位置编码
2. 


周末:
1. 说需要剔除异常数据，感觉同样膜厚的不同数据如果差别不大都可以保留，差别很大就那段时间段全剔除？

背背正正 后俩厚于前俩 这个信息暂时不知道咋用

2. 每一炉的第一层数据 仔细研究下






# 0823 ~ 0828 本周 to do list
1. 是否拆分出model1+2的节奏，model12的是否区分清洗周期[单个清洗周期内也存在一个X对应多个y的问题]  条件概率的实验试试看 等  
2. 大概周四晚上 把目前的实验结论整理下给到co哥  然后xixi那边顺便一起澄清下
3. 





0823~0828周报
0823: 
1. 简单搭一个rnn的模型出来先, 就直接 thick10 输入, lab81输出呗.
单独对每个清洗周期建模rnn 隐含状态则是有限的(比如本周期内61条数据, 则t=0~60) [done.]

2. 测试数据上来, 在model1的loss还是很大, 这个还要好好思考下!!!
猜想还是因为数据中存在一对多关系, 导致学习所得的模型预测鲁棒性很差...


rnn思路:
# 正向
xt ht ot:

Input:  torch.Size([batchsize, seq_len, x_feature_len])
Output:  torch.Size([batchsize, seq_len, hidden_out_dim])
Hidden:  torch.Size([1, batchsize, hidden_out_dim])       # 1表示最后一个time_t
Hidden, 每个time_t, 每个样本, 会有不同的81output, 感觉是合理的.

1. xt 就可以是: 10 thickness
   ht 可以直接套用我们之前的 mlp, 把 10维thickness 映射到 81维lab曲线
   ot 是不同样本的各个81维lab回归结果
   sqe_len取各个data_cycle中数据量最多的值, 比如88(认为可以有0~87种不同的机器隐含状态)
   这样即用到了全量的数据, 没有独立各个清洗周期去建模. 

风险, 不一定能收敛, 只有15条数据的cycle 和 有30条数据的cycle 之间, 前面公共的15个 ht_i, 是可以训成同样"模式"的嘛?

# 反向
1. 可以尝试 rnn 的反向固定weights, 微调输入改变输出
2. 也可以在输入端作参数搜索 得到最佳的输出 即认为可以用这套输入设置来镀膜得到理想lab曲线(搜索的思路.)



0824 
1. 条件概率的赶紧实践出来  [但感觉优先级没那么高 理清楚数据XY一对一先] [其实也就是xixi的那个方案]
2. rnn 不收敛???
3. 写完了给co哥的项目截至目前尝试过的方案
4. 蔡司膜色曲线跟客户对齐了技术规格, lab曲线的回归接受误差和正背差判定方案都定下了.


0825:
1. xixi的方案train起来了, [在做输入段的部分维度固定不更新参数, 仅微调10层deta膜厚部分 done.]
10层deta thickness 幅度很小, 可能本周期内数据就没那么异常? 一会换一个异常样本多的周期试试??
2. 跟售前(付帅)对齐蔡司部分的ppt 根据售前的反馈意见修改ppt [已反馈]
3. rnn 再调下 [没来得及做]


0826:
1. 跟co哥过一遍蔡司尝试过的所有方案, 看看算法上还可以尝试的思路
2. 软件那边对接 写两个api, 请求数据和查询结果给他们.
3. rnn 方案优化 [co哥: 优先级靠后 ].. 

co 哥会议结论: 
1. 根据重复异常数据, 在采样值.csv文件里找出重要信息列的特征
志哥: 脚本通用化一些，不一定局限在异常样本，设置值和执行采样值可以全量跑一下看看关联
2. 继续xixi的方案, 不区分周期使用所有数据, 继续添加X的特征(条件概率思路) nn实现  [统一使用第一层数据..   done. 效果不佳..]
3. deta + 条件概率的思路 可以套用到model1上 (现在做的是一步到位,直接X'->lab曲线)
4. rnn 优先级靠后


0827~0828: 
1. 膜色缺陷的, rgb->lab 开始写代码解方程
rgb * M = xyz, xyz->lab   M 是需要矫正的矩阵
客户的痛点是: 一图多谱. 客户采样拍摄照片时, 因打光, 角度等原因, 导致本条样本的rgb值不百分百准确. 不同的真实测量到的lab曲线, 可能被拍出了不同的rgb颜色?
rgb->lab曲线, 如上说的, rgb与真实样本测量所得lab曲线存在一对多关系, 这样模型肯定是学不好的...  [done.]
色卡对比???  扯淡呢...

https://blog.csdn.net/lz0499/article/details/77345166
标准的rgb转xyz:
outXyz[0] = 100 * (sr * 0.412453 + sg * 0.357580 + sb * 0.180423);
outXyz[1] = 100 * (sr * 0.212671 + sg * 0.715160 + sb * 0.072169);
outXyz[2] = 100 * (sr * 0.019334 + sg * 0.119193 + sb * 0.950227);
只要是固定的同样的打光, 这9个参数就不会变的, 样本之间可共享..
多几个样本, 组合出大概9个方程, 大概是可以把9个参数解出来的吧...
9个方程, 解9个变量?   3条样本即可解决~ [done.]


3. 大概率会及时做的: 
1. 膜色缺陷 解方程下~ [初步done. 精度还需调优..]


1. 处理正背面数据.. [数据貌似是有bug.. 感觉用不起来...]
2. 根据重复异常数据, 在采样值.csv文件里找出重要信息列的特征
志哥: 脚本通用化一些，不一定局限在异常样本，设置值和执行采样值可以全量跑一下看看关联
       集中看下有意义的25列数据, 做一点时序特征工程..
3. 学习下数模型: lightgbm
4. xixi方案, 思考下, 为什么model前向拟合的蛮好的, 但是deta修改量那么微小, 这不大合理... 

# 0827 
# 1. 输出一个单双面数据规范文档给蔡司 希望数据尽量规整 减轻数据清洗难度 [done.]                                         
2. 扫码器那边貌似有一个类似蔡司的场景 可能会接下来做... 



0828:
1. 正背面数据负数处理下, 用起来试试, 看看效果能怎么样
       1. 正背面的代码先通路搭起来,   [half done ...]
       数据量太少, 正面thick-lab数据是27, 不重复thickness设置是13种...  [可先不做别的处理吧.. 还是在双面数据上探索下 3. 4. 先~]
       正背面肯定是需要区分开建模的, 不然怎么做到: 正背面不同的膜厚设置值, 但得到无差的正背两条膜色曲线.  
              [这可以说明膜厚值到lab曲线是多解问题, 还是机器正背面有着不同的状态?  
              都不是, 李工解答: 镜片正背曲率不同, 背面距离材料远, 所以需要设置多一些， 才能达到同样的[实际]膜厚.  所以还是要看膜厚设置值对机器sensor影响的情况..]
              我记得之前提到的晶振片 第二面正背都比第一面正背会厚一些，所以设置值可以相对调小点. 可能晶振片使用的次数是个很重要的影响量。 

李工: 你说的晶振问题，是的，正如你记忆一样。随着膜料沉积，灵敏度下降，同样的膜厚设置实际会偏多，所以一般第二个一般比第一个需要减一点

2. 膜色缺陷的, 解方程那块再思考下。 把现在的M前向算一下所有的lab值看看和真实值的误差 [和莫宇哥请教下...]



3. 根据重复异常数据, 在采样值.csv文件里找出重要信息列的特征
志哥: 脚本通用化一些，不一定局限在异常样本，设置值和执行采样值可以全量跑一下看看关联
      [4条异常样本，看看sensor中哪些改变lab最大。 正常和异常样本，看看deta thickness怎么改变各种sensor]
      集中看下有意义的25列数据, 做一点时序特征工程..

1. *** [今天集中看下膜厚设置值 对 晶振频率那列的影响.]
2. *** 膜色缺陷的, rgb 转 lab 颜色空间 调研.. 
最早那批数据的结果 [非0812数据]
---------- dir: 1 ----------
all data size: 17
diff in [-0.5, 0.5] data size: 13

---------- dir: 2
all data size: 20
diff in [-0.5, 0.5] data size: 19

---------- dir: 3
all data size: 19
diff in [-0.5, 0.5] data size: 16

---------- dir: 4
all data size: 20
diff in [-0.5, 0.5] data size: 17

---------- dir: 5
all data size: 20
diff in [-0.5, 0.5] data size: 14

---------- dir: 6
all data size: 20
diff in [-0.5, 0.5] data size: 11


[0812数据再跑跑..]
跑了已经.. 
有6个rgb值, 重叠和外围区域的意思?
在rgb2lab.py中数据测试过了, 效果还不如上一批数据.
[项目代码在git上建repo了..]

moyu:
是有这个可能，不过感觉他们的rgb2lab的实际含义和我们不太一样，强行找非线性拟合曲线，我担心会过拟合
我的思路是，把gt和pred转到一个颜色空间，再做拟合
这样维度应该能统一起来，因为映射是连续的，只要在同一颜色空间足够接近就行
但是单纯看网上的映射，在同一颜色空间，没有找到太多联系



0829 在家吧.. 
4. 学习下树模型: lightgbm

5. xixi方案, 思考下, 为什么model前向拟合的蛮好的, 但是deta修改量那么微小, 这不大合理... 

maybe delay..
6. 工程那边, 接口搞定下  问下志哥有没参考模板.


0828 结论:
1. 正背一点过需要分开建模 或者说正背膜厚到正背的sensor肯定是不一样的.. [李工: 镜片正背曲率不同, 背面距离材料远, 所以需要设置多一些， 才能达到同样的[实际]膜厚]
       着重抓一下晶振频率这个信息!!! [只看8个std好像没太大差异?????]



### 紧急要做的

2. *** 当前的这个 M 在所有数据上的误差, 统计下.. [done.]   0.78左右的精度.

1. *** 直接['33121051807', '33121051801'] 这两条数据集中看看. 同膜厚设置, lab曲线相差很大, 可挖掘下sensor中哪些影响lab曲线最严重..
[std差异暂时没看出很大, ] 



